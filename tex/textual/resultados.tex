\chapter{Resultados} \label{ch:Resultados}
%  Os resultados seguem a metodologia

% Definir qual o top_k utilizado
% Verificar em Were2014 novamente
% Padrão do zettair (se não me engano é 20)
% Artigo de fulano não diz

% Capítulo de Resultados 

% -> Introdução: "Este capítulo apresenta os resultados obtidos e discute-os..." 
Este capítula apresenta os resultados obtidos neste estudo investigativo do desempenho de atributo de RI em classificadores de Mineração de Texto.

Nas subseções a seguir primeiro é abordada a configuração experimental utilizada para realizar o estudo, e logo em seguida é apresentada uma visão geral das soluções selecionadas dos corpus DB\_AUTHORPROF e DB\_HYPERPARTISAN, onde os pré-processamento realizado e os classificadores utilizados em cada uma das soluções são descritos brevemente.
Por fim, são apresentados os resultados mensurados por meio das medidas escolhidas para avaliação de desempenho, na subseção X estão as medidas de desempenho das ferramentas de armazenamento e indexação e na subseção são expostas as medidas de desempenho dos classificadores.

% Na subseção a seguir são abordados os resultados referentes às ferramentas de indexação.
% Na subseção posterior são abordados os resultados referente aos desempenho das variáveis de RI em classificadores.

\section{Configuração experimental} \label{sec:resex1}
% 4.0 Setup experimental 

	Para programação e execução dos experimentos foi utilizado o sistema computacional disponível para o autor, com a configuração disposta na Tabela 4.1.

	As ferramentas de armazenamento e indexação receberam os mesmos parâmetros de refinamento na configuração de suas funções BM25, sendo estes configurados em $k_1 = 1.2$, $k_3 = 0$ e $b = 0.75$.
	O parâmetro $k_3$, para escalonar a frequência de termos na consulda, é exclusivo para o Zettair, as demais ferramentas não implementam este parâmetro.

	% Fixação do número aleatório do Python e das bibliotecas utilizadas nas soluções, quando isto não era feito originalmente, para permitir reproducibilidade exata dos resultados obtidos. 

\section{Visão geral das soluções selecionadas} \label{sec:resex1}
	% Falar brevemento sobre o pré-processamento;
	% Falar sobre o classificador utilizado; e
	% Indicar o Notebook de cada solução para mais detalhes
	\subsection{Soluções para o corpus DB\_HYPERPARTISAN}

	\subsection{Soluções para o corpus DB\_AUTHORPROF}

\section{Desempenho das ferramentas de armazenamento e indexação} \label{sec:resex1}
	Para cálculo das variáveis TIME_INDEX e TIME_QUERY, conforme sugeridas no Capítulo 3, foi utilizada a linguagem de programação Python na qual foi implementada uma classe abstraindo a indexação e cálculo das variáveis de RI nas 3 ferramentas de Indexação, chamada IndexToolManager. 

	Esta classe foi central para todo o estudo. 

	\subsection{Tempo de indexação}
		Para cálculo das variáveis TIME_INDEX foi criado um script python nomeado time_index.py, o qual utilizou da classe IndexToolManager em duas funções feitas para executar a indexação dos banco de dados, DB_AUTHORPROF e DB_HYPERPARTISAN, nas 3 ferramentas, ARANGO, ELASTIC e ZETTAIR. 

		

		Como as ferramentas ARANGO e ELASTIC se assemelham bastante a sistemas gerenciadores de bancos de dados, preparados, inclusive, para distribuição geográfica dos dados, há de ser citada essa grande diferença deles para o ZETTAIR, este último que é somente um sistema para Indexação em lotes e consulta local dos dados, não permitindo, por exemplo, adição de novos documentos em um índice. A ação de inserção unitária é um procedimento comum em SGBDs. 

		

		A operação de indexação foi executada de dois modos, em lote e unitária, sendo que o ZETTAIR só permite a inserção em lote. 

		

		Na Figura 4.1 podem ser vistos os resultados do tempo para inserção em lote dos documentos dos corpus  em cada ferramenta. 

		

		O ZETTAIR é a ferramenta mais rápida para completar a indexação de ambos os corpus selecionados, levando somente 2,x segundos para indexar os 300 mil documentos do corpus DB_AUTHORPROF. 

		Dentre os SGBDs avaliados, vemos que o ELASTIC tem  melhor desempenho que o ARANGO para inserções em lote, gastando 15 segundos para indexar os 300 mil documentos. 

		

		Para operação de inserção unitária foi levado em conta o tempo total para indexação dos 300 mil documentos, inseridos em sequência, na Figura 4.2 estão dispostos os tempos totais para indexação de todos os documentos dos corpus com ambas ferramentas. 

	\subsection{Tempo de consulta}

\section{Desempenho dos classificadores com atributos de RI} \label{sec:resex1}

	\subsection{DB\_HYPERPARTISAN}

	\subsection{DB\_AUTHORPROF}

% Fluxograma das alterações feitas nos códigos com exemplos de trechos alterados
% Rosalvo disse que é para colocar no Apêndice

% Zettair, colocar detalhe dos modos de operação para consulta, iterativa e consulta única

% ganho de informação das 6 variáveis nas soluções

% Citar as técnicas só de um, descrições, citar algum livro ou página

% Criar rede neural para comparar à solução do DB_AUTHORPROF à parte 

