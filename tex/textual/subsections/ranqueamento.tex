\subsection{Ranqueamento} \label{subsec:Ranqueamento}
Devido à limitação dos métodos booleanos de somente retornar resultados conforme a presença ou não dos termos da consulta nos documentos \cite[p.~100]{Manning2008IIR}, foi proposto em 1957 por Luhn e em 1959 por Maron \textit{et al.} uma abordagem de recuperação ranqueada \cite[p.~1446]{Sanderson2012THIRR} a qual, em contraste com recuperação booleana, baseada nos termos de consulta estabelecia uma pontuação para cada artigo de modo probabilístico e retornava os artigos de modo ordenado e demonstraram que essa técnica sobressaía a recuperação booleana.

% Explicar o funcionamento de uma recuperação ranqueada, como é feito esse ranqueamento?
O procedimento fundamental para ranqueamento dos documentos, conforme os termos de consulta, consiste na atribuição de pontuação aos documentos a partir da contabilização do número de aparições (chamada de frequência) de cada um dos termos no documento.
Essa pontuação é calculada considerando que além da frequência do termo, denotada como $\text{tf}_{\text{\textit{t},\textit{d}}}$ que é o número de ocorrências do termo \textit{t} em um documento \textit{d}, existe também a sua relevância, que depende do número de aparições do termo na coleção de documentos inteira.
Quanto mais um termo aparece na coleção menos relevante ele é, e este valor de relevância é denotado por $\text{idf}_{\text{\textit{t}}}$ que é o inverso da frequência de um termo \textit{t} em uma coleção de documentos.
Segundo \citeonline[p.~108]{Manning2008IIR} este valor da relevância é calculado do seguinte modo:

\begin{equation}
    \text{idf}_{\text{\textit{t}}} = \log{\frac{N}{\text{df}_{\text{\textit{t}}}}}.
\end{equation}

O valor resultante da relação entre a frequência do termo e o inverso da frequência nos documentos é chamado de $\text{tf-idf}_{\text{\textit{t},\textit{d}}}$ (\textit{term frequency-inverse document frequency}), sendo este valor um dos pesos mais utilizados para ranqueamento \cite[p.~107--110]{Manning2008IIR}, e é calculado  como segue:
\begin{equation}
    \text{tf-idf}_{\text{\textit{t},\textit{d}}}  = \text{tf}_{\text{\textit{t},\textit{d}}} \times \text{idf}_{\text{\textit{t}}}.
\end{equation}

\input{tex/table/tf-idf-exemplo.tex}

Na Tabela \ref{tab:exemplo-tf-idf} temos um exemplo de cálculo dos valores de tf-idf para posterior cálculo da pontuação para ranqueamento, conforme alguma determinada consulta. 
A pontuação de um documento \textit{d} é a soma dos pesos de tf-idf de cada termo \textit{t} em \textit{d}, sendo os termos \textit{t} presentes na consulta realizada \cite[p.~109]{Manning2008IIR}, representamos esse cálculo do seguinte modo:

\begin{equation}
    \label{eq:pontuação-simples-tf-idf}
    \text{Pontuação(\textit{q},\textit{d})} = \sum_{\textit{t} \in \textit{q}}^{} \text{tf-idf}_{\text{\textit{t},\textit{d}}}.
\end{equation}

% Quando uma consulta é feita são utilizados os valores 
% (onde Pontuação({\textit{auto},\textit{car}},DocX))  

Utilizando a Equação \ref{eq:pontuação-simples-tf-idf} uma consulta com os termos \textit{auto car} retornaria no seu ranqueamento os documentos com a seguinte pontuação, calculamos $\text{Pontuação(\{\textit{auto},\textit{car}\},D\textsubscript{x})}$ para cada documento, por exemplo:
\begin{itemize}
    \setlength\itemsep{-0.2em}
    \item D\textsubscript{1}: 50,79
    \item D\textsubscript{2}: 75,24
    \item D\textsubscript{3}: 39,60
\end{itemize}

A ordenação dos documentos apresentados como resultado à consulta \textit{auto car} seria então a seguinte: 1\textordmasculine{} - D\textsubscript{2}; 2\textordmasculine{} - D\textsubscript{1}; e 3\textordmasculine{} - D\textsubscript{3}, que se observamos a Tabela \ref{tab:exemplo-tf-idf} é um bom resultado, já que o D\textsubscript{2} contém uma grande frequência do termo \textit{auto} e o D\textsubscript{3} não possui este termo.


Ao longo dos anos foi demonstrada a superioridade da recuperação ranqueada sobre a recuperação booleana \cite{Jones:1981:IRE:539571}, e são as técnicas de recuperação ranqueadas que trazem maior interesse para a área de Mineração de Textos, em específico estamos interessados nos modelos vetoriais e os modelos probabilísticos de RI que são evoluções da recuperação ranqueada.
% ESTOU PENSANDO EM JÁ CITAR O BM25 no parágrafo acima.
% -- Em algum ponto mencionar que Recuperação de Informação (Information Retrieval) não deve ser confundido com Procura de Informação (Information Search), pois a Procura de Informação é o campo que estuda a interação das pessoas com sistemas de recuperação de informação.

\subsubsection{Modelo de espaço vetorial} \label{subsubsec:Modelo-espaço-vetorial}
% O modelo de espaço vetorial.

% Modelo vetorial

%   	Tirado da cabeça
%     		Utiliza do vetor gerado pelo cálculo dos tf-idf calculados para cada palavra a partir da coleção inteira, e então define que o nível de similaridade entre uma consulta e um arquivo é dado pelo cosseno do ângulo entre os dois vetores.

%   	Do livro do Baeza
    A modelo vetorial surge a partir das limitações do modelo Booleano, que não considera frequência dos termos, e nele são representados um conjunto de documentos num espaço vetorial comum \cite[p.~110]{Manning2008IIR}, oferecendo a possibilidade de resultados parciais por meio da atribuição de pesos não binários para os termos da consulta e também para os termos presentes nos documentos, que são utilizados para determinar o grau de similaridade entre cada documento armazenado no sistema e uma determinada consulta \cite[p.~77]{Baeza-Yates2011}.
    
    Neste modelo os resultados são apresentados em ordem decrescente de similaridade, considerando a correspondência parcial, e não obrigatoriamente total, com os termos da consulta, provendo assim uma resposta mais precisa para as necessidades de informação do usuário.
    A similaridade nos modelos de espaço vetorial é tratada como uma noção de relevância, e a principal premissa é de que a relevância de um documento em relação a uma consulta está correlacionada com a similaridade entre o documento e consulta \cite[p.~110]{Zhai2016TDMA}.
    
    Segundo \citeonline[p.~77]{Baeza-Yates2011}, os pesos $w_{i,j}$ associados com um par termo-documento são não negativos e não binários.
    Os termos de indexação são considerados mutualmente independentes e são representados como vetores unitários de um espaço $t$-dimensional, aonde $t$ é número total de termos de indexação.
    A representação de um documento $d_j$ e uma consulta $q$ são vetores $t$-dimensionais representados como segue nas Equações \ref{eq:vetor-pesos-documento} e \ref{eq:vetor-pesos-consulta} abaixo:
    \begin{equation}
        \label{eq:vetor-pesos-documento}
		\vec{d_j} = (w_{1,j}, w_{2,j}, \cdots , w_{t,j})
    \end{equation}
    \begin{equation}
        \label{eq:vetor-pesos-consulta}
		\vec{q} = (w_{1,q}, w_{2,q}, \cdots , w_{t,q})
    \end{equation}
    
    O valor $\text{tf-idf}_{\text{\textit{t},\textit{d}}}$ (apresentado na Subseção \ref{subsec:Ranqueamento}) é um dos padrões de pesos mais comuns utilizados, sendo aplicado diretamente para os pesos de cada termo do documento $d_j$.
    E como $w_{i,q}$ é o peso associado com o par termo-consulta $(k_i, q)$, a aplicação do $\text{tf-idf}_{\text{\textit{t},\textit{d}}}$ vira $\text{tf-idf}_{k_i\text{,}\textit{q}}$ para os pesos associados à consulta $q$ \cite[p.~77--78]{Baeza-Yates2011}.
    
    Logo, tanto o documento $d_j$ quanto uma consulta $q$ feita pelo usuário são representados como vetores t-dimensionais como ilustrado na Figura \ref{fig:similaridade-cosseno}, posteriormente modulados pelos pesos associados.
    
    \input{tex/figure/cosine-sim.tex}
    
    A avaliação do grau de similaridade entre esses vetores, sendo esta correlação, ou pontuação que o documento $d_j$ vai receber para a consulta $q$, quantificada pelo cosseno do ângulo entre esses dois vetores, conforme demonstra a Equação \ref{eq:pontuação-similaridade-cosseno} \cite[p.~78]{Baeza-Yates2011}.
    \begin{equation}
        \label{eq:pontuação-similaridade-cosseno}
		\text{Pontuação}(\vec{d_j}, \vec{q}) = \frac{\vec{d_j} \bullet \vec{q} }{ \norm{\vec{d_j}} \times \norm{\vec{q}} }
    \end{equation}

    % falta falar sobre as vantagens e desvantagens citadas pelos autores
    % [falta falar sobre as vantagens e desvantagens citadas pelos autores] feito
    
    \citeonline[p.~79]{Baeza-Yates2011} apontam como vantagens do modelo vetorial:
    \begin{itemize}
        \item \textbf{Melhora da qualidade dos resultados} devido à esquemática de pesos utilizada;
        
        \item Capacidade de \textbf{correspondência parcial} possibilita que documentos \textit{próximos} da consulta sejam retornados;
        
        \item \textbf{Organização dos resultados pelo grau de similaridade com a consulta} devido à fórmula de ranqueamento pelo cosseno dos vetores;
        
        \item \textbf{Normalização dos tamanhos dos documentos} embutida.
    \end{itemize}
    
    E como principal desvantagem apontam a presunção de que os termos indexados são mutualmente independentes, sendo esta tarefa de considerar a dependência dos termos algo bastante complicado e que pode trazer resultados ruins caso não seja feito de modo adequado.
    % Pontuações por Baeza, 1) a esquemática de pesos dos termos melhora a qualidade, 2) sua capacidade de correspondência parcial permite a recuperação de documentos que se aproximam das consultas, 3) o ranqueamento pelo cosseno dos vetores organiza os resultados pelo seu grau de similaridade com a consulta, 4) possui normalização dos tamanhos dos documentos embutida.
    % desvantagem: assume que os termos indexados são mutualmente independentes (porém ele cita que considerar a dependência de termos é uma tarefa complicada que se não for feito do modo apropriado pode levar a resultados ruins).

\subsubsection{Modelo probabilístico}  \label{subsubsec:Modelo-probabilístico}
% Fazer resumo de como se chegou ao BM25, um método probabilístico criado pelo Kevin Spack e pelo Jones em 85 eu acho, que depois deu início ao BM11 e ao BM15, a junção dos dois deu origem ao BM25, e então o Okapi BM25 surgiu logo após com a adição de técnica de alteração dos pesos dos termos desenvolvida por Okapi.
    Existem diferentes modelos probabilísticos para RI, como por exemplo o modelo linguístico, o modelo de divergência do aleatório (\textit{divergence from randomness}), e o Framework de Relevância Probabilística (também chamado de modelo clássico) \cite[p.~87]{Zhai2016TDMA}, que é o mais conhecido por ter dado origem à função BM25 para ranqueamento de documentos \cite[p.~334--335]{robertson_probabilistic_2010} \cite[p.~111]{Zhai2016TDMA}, a qual será nosso foco de abordagem.
    
    % As necessidades de informações do usuário são traduzidas em representações de consultas e os documentos de interesse são traduzidos em representações de documentos, e assim os sistemas de RI tentam determinar o quão bem os documentos satisfazem essas necessidades de informação.
    % No entanto, dadas a representações de consulta e de documentos, os sistemas de RI possuem um tanto de incerteza sobre quais documentos tem conteúdo relevante. 
    % Para fazer essa decisão os modelos probabilísticos baseiam-se na teoria probabilística que fundamenta o raciocínio em cima de incertezas \cite[p.~201]{Manning2008IIR}.
    
    Como já abordado, os sistemas de RI tentam determinar o quão bem os documentos satisfazem as necessidades de informação do usuário, porém existe um grau de incerteza sobre quais documentos tem conteúdo relevante. 
    Partindo desse princípio da existência da incerteza na relevância dos documentos temos os modelos probabilísticos, que baseiam-se na teoria probabilística que fundamenta o raciocínio em cima de incertezas \cite[p.~201]{Manning2008IIR}. 
    
    Nos modelos probabilísticos a função de ranqueamento é definida baseada na probabilidade que um documento $d$ é relevante para uma consulta $q$, ou que $P(R = 1| d,q)$ onde $R \in \{0, 1\}$ é uma variável binária aleatória que denota a relevância \cite[p.~111--112]{Zhai2016TDMA}, sendo esta a base para o princípio do ranqueamento probabilístico (PRP) \cite[p.~203]{Manning2008IIR}.
    
    O Framework de Relevância Probabilística deu origem ao modelo de independência binária (BIM), aos modelos de \textit{feedback} de relevância, ao nosso caso de interesse, o BM25, e também a diversas variações do BM25 \cite{robertson_probabilistic_2010}. 
    
    O BIM faz a implementação do princípio de ranqueamento probabilístico com documentos e consultas sendo representados por vetores binários de incidência dos termos, podendo assim ser comparado ao modelo Booleano \cite[p.~204]{Manning2008IIR}.
    A evolução das implementações dos modelos probabilísticos clássicos levou à função de recuperação conhecida como \textbf{Okapi BM25}, ou simplesmente BM25, que integra os conceitos do modelo vetorial apresentado na Subsubseção \ref{subsubsec:Modelo-espaço-vetorial}, como frequência dos termos, normalização de tamanho, e correspondência parcial.
    Devido à sua similaridade com os modelos vetoriais, alguns autores, como \citeonline[p.~111]{Zhai2016TDMA}, apresentam a função BM25 função junto à dos modelos vetoriais.
    
    Toda teoria probabilística do PRP, que fundamenta os modelos do Framework de Relevância Probabilística, inclusive o BM25, é extensa e portanto não vamos desenvolvê-la detalhadamente aqui.
    
     necessário citar que o BIM
    
    
% Probability theory provides a principled foundation for such reasoning under uncertainty
% Colocar fluxograma do BM25